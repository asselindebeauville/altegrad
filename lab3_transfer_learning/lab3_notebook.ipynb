{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> Kyllian Asselin de Beauville\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntoken: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "        '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(num_embeddings=ntoken, embedding_dim=nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout) # fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=nhid, nhead=nhead, dim_feedforward=nhid, dropout=dropout) # fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers) # fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src) # fill me\n",
        "        output = self.transformer_encoder(src, src_mask) # fill me\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses) # fill me\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout) # fill me\n",
        "        self.classifier = ClassificationHead(nhid, nclasses) # fill me\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src, src_mask) # fill me\n",
        "        # classifier model\n",
        "        output = self.classifier(x) # fill me\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317abfda-e989-4f1c-818f-c0730b1ed55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06a152e-b0a6-4a80-ad93-18e458adb149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 21:40:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-31 21:40:47 (29.2 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5740bd52-7e51-41a3-8629-c917191ca607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] = idx + 4 # fill me\n",
        "\n",
        "ind2token = {ind: token for token, ind in token2ind.items()} # fill me\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [self.token2ind.get(token, self.token2ind[\"<oov>\"]) for token in sequence] # fill me (construct the input sequence using token2ind, sequence and special tokens)\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        # we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): # step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) # step 2\n",
        "        if task == 'classification':\n",
        "            # last vector only\n",
        "            output = output[-1] # fill me\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = data[1] # fill me\n",
        "        target = target.to(device)\n",
        "        loss =  criterion(output, target) # fill me, Cross entropy check next cells\n",
        "        # fill me step 3\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        # fill me step 4\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "ntokens = len(token2ind) # fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization parameters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806d53af-d7eb-4e7a-9509-e7ba04bfb957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 21:40:48--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-31 21:40:49 (208 MB/s) - ‘pretraining_subset.txt’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffe7a1b-28ab-4e08-9f0b-13b6a9433f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.33722 | ppl 1536.434\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.48784 | ppl  657.101\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.20090 | ppl  493.195\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.02221 | ppl  412.488\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.92588 | ppl  374.609\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.82240 | ppl  337.783\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.50985 | ppl  247.113\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.47146 | ppl  237.807\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.43845 | ppl  230.085\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.43223 | ppl  228.659\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.36358 | ppl  213.488\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.33919 | ppl  208.344\n"
          ]
        }
      ],
      "source": [
        "# pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): # step 5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\", # fill me\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32695667-e6e8-46f9-9db4-2b8763756b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 21:45:40--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   373MB/s    in 0.2s    \n",
            "\n",
            "2023-10-31 21:45:40 (373 MB/s) - ‘pretrained_model_4layers.pt’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "# load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "# load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad059608-3e49-438c-b9bd-f11ff59f7efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "--2023-10-31 21:45:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-31 21:45:47 (45.4 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') # load sentencepiece model\n",
        "\n",
        "# examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = out[-1].argmax(-1).item() # fill me\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    # to be implemented\n",
        "    generated_sentence = sent\n",
        "    for _ in range(max_len):\n",
        "        next_token_ind, _ = infer_next_token(generated_sentence)\n",
        "        encoded_next_token = ind2token[next_token_ind]\n",
        "        decoded_next_token = s.decode_pieces([encoded_next_token])\n",
        "        if encoded_next_token == \"<eos>\":\n",
        "            break\n",
        "        if encoded_next_token[0] == \"▁\":\n",
        "            generated_sentence += \" \"\n",
        "        generated_sentence += decoded_next_token\n",
        "    return generated_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38c0dc37-fba9-4d1d-fae9-a7f88a9729ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0585cda-680a-42cc-b281-7d2fe99c9e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 21:45:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "train.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-31 21:45:47 (57.2 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-31 21:45:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 21:45:47 (23.9 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2023-10-31 21:45:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-31 21:45:48 (74.4 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-31 21:45:48--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 21:45:48 (47.5 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    # to be implemented\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "            input = data[0].to(device)\n",
        "            output = model(input, src_mask)\n",
        "            output = output[-1]\n",
        "            output = output.view(-1, output.shape[-1])\n",
        "            pred = output.argmax(-1)\n",
        "            target = data[1].to(device)\n",
        "            correct_predictions += (pred == target).sum().item()\n",
        "            total_predictions += target.size(0)\n",
        "    return correct_predictions / total_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "# save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa82404-81e9-4a3c-ad04-94eb2f06a4a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Training FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.73301 | ppl    2.081\n",
            "| epoch   1 |   100/  200 steps | loss 0.72593 | ppl    2.067\n",
            "| epoch   1 |   150/  200 steps | loss 0.72112 | ppl    2.057\n",
            "| epoch   2 |    50/  200 steps | loss 0.70588 | ppl    2.026\n",
            "| epoch   2 |   100/  200 steps | loss 0.64587 | ppl    1.908\n",
            "| epoch   2 |   150/  200 steps | loss 0.64813 | ppl    1.912\n",
            "| epoch   3 |    50/  200 steps | loss 0.37714 | ppl    1.458\n",
            "| epoch   3 |   100/  200 steps | loss 0.44867 | ppl    1.566\n",
            "| epoch   3 |   150/  200 steps | loss 0.34531 | ppl    1.412\n",
            "| epoch   4 |    50/  200 steps | loss 0.13380 | ppl    1.143\n",
            "| epoch   4 |   100/  200 steps | loss 0.21102 | ppl    1.235\n",
            "| epoch   4 |   150/  200 steps | loss 0.15352 | ppl    1.166\n",
            "| epoch   5 |    50/  200 steps | loss 0.04182 | ppl    1.043\n",
            "| epoch   5 |   100/  200 steps | loss 0.03849 | ppl    1.039\n",
            "| epoch   5 |   150/  200 steps | loss 0.03091 | ppl    1.031\n",
            "| epoch   6 |    50/  200 steps | loss 0.00421 | ppl    1.004\n",
            "| epoch   6 |   100/  200 steps | loss 0.00258 | ppl    1.003\n",
            "| epoch   6 |   150/  200 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   7 |    50/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   7 |   100/  200 steps | loss 0.00518 | ppl    1.005\n",
            "| epoch   7 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   8 |    50/  200 steps | loss 0.00025 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00037 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.02135 | ppl    1.022\n",
            "| epoch  14 |    50/  200 steps | loss 0.00279 | ppl    1.003\n",
            "| epoch  14 |   100/  200 steps | loss 0.00177 | ppl    1.002\n",
            "| epoch  14 |   150/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.83663 | ppl    2.309\n",
            "| epoch   1 |   100/  200 steps | loss 0.69064 | ppl    1.995\n",
            "| epoch   1 |   150/  200 steps | loss 0.62166 | ppl    1.862\n",
            "| epoch   2 |    50/  200 steps | loss 0.47890 | ppl    1.614\n",
            "| epoch   2 |   100/  200 steps | loss 0.46100 | ppl    1.586\n",
            "| epoch   2 |   150/  200 steps | loss 0.44372 | ppl    1.558\n",
            "| epoch   3 |    50/  200 steps | loss 0.32900 | ppl    1.390\n",
            "| epoch   3 |   100/  200 steps | loss 0.36410 | ppl    1.439\n",
            "| epoch   3 |   150/  200 steps | loss 0.42778 | ppl    1.534\n",
            "| epoch   4 |    50/  200 steps | loss 0.22917 | ppl    1.258\n",
            "| epoch   4 |   100/  200 steps | loss 0.33956 | ppl    1.404\n",
            "| epoch   4 |   150/  200 steps | loss 0.28209 | ppl    1.326\n",
            "| epoch   5 |    50/  200 steps | loss 0.11978 | ppl    1.127\n",
            "| epoch   5 |   100/  200 steps | loss 0.21975 | ppl    1.246\n",
            "| epoch   5 |   150/  200 steps | loss 0.22791 | ppl    1.256\n",
            "| epoch   6 |    50/  200 steps | loss 0.13615 | ppl    1.146\n",
            "| epoch   6 |   100/  200 steps | loss 0.16149 | ppl    1.175\n",
            "| epoch   6 |   150/  200 steps | loss 0.10097 | ppl    1.106\n",
            "| epoch   7 |    50/  200 steps | loss 0.09002 | ppl    1.094\n",
            "| epoch   7 |   100/  200 steps | loss 0.09609 | ppl    1.101\n",
            "| epoch   7 |   150/  200 steps | loss 0.05426 | ppl    1.056\n",
            "| epoch   8 |    50/  200 steps | loss 0.04440 | ppl    1.045\n",
            "| epoch   8 |   100/  200 steps | loss 0.03666 | ppl    1.037\n",
            "| epoch   8 |   150/  200 steps | loss 0.00341 | ppl    1.003\n",
            "| epoch   9 |    50/  200 steps | loss 0.00123 | ppl    1.001\n",
            "| epoch   9 |   100/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00399 | ppl    1.004\n",
            "| epoch  10 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00017 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00291 | ppl    1.003\n",
            "| epoch  11 |    50/  200 steps | loss 0.00126 | ppl    1.001\n",
            "| epoch  11 |   100/  200 steps | loss 0.00142 | ppl    1.001\n",
            "| epoch  11 |   150/  200 steps | loss 0.02037 | ppl    1.021\n",
            "| epoch  12 |    50/  200 steps | loss 0.04559 | ppl    1.047\n",
            "| epoch  12 |   100/  200 steps | loss 0.03885 | ppl    1.040\n",
            "| epoch  12 |   150/  200 steps | loss 0.00949 | ppl    1.010\n",
            "| epoch  13 |    50/  200 steps | loss 0.00230 | ppl    1.002\n",
            "| epoch  13 |   100/  200 steps | loss 0.00767 | ppl    1.008\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00468 | ppl    1.005\n",
            "| epoch  15 |    50/  200 steps | loss 0.00297 | ppl    1.003\n",
            "| epoch  15 |   100/  200 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00938 | ppl    1.009\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        # load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        # load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Training FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "480c132b-606a-4600-e975-97b416ed8d11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = range(1, epochs + 1)\n",
        "plt.plot(x, from_scratch_valid_acc, label=\"From scratch\")\n",
        "plt.plot(x, pretrained_valid_acc, label=\"Pretrained\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}